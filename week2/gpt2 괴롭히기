{"cells":[{"cell_type":"markdown","metadata":{"id":"42cWI3_j6oWK"},"source":["# GPT-2 모델 사용해보기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UgJaSoU06oWL"},"outputs":[],"source":["# 코드 한번에 보기\n","from transformers import pipeline\n","\n","huggingface_model_name = \"skt/kogpt2-base-v2\"\n","pipe = pipeline(\"text-generation\", model=huggingface_model_name)\n","pipe('', max_new_tokens=50)"]},{"cell_type":"markdown","metadata":{"id":"UPYaOg1n6oWM"},"source":["### 생성 코드 더 자세히 살펴보기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9YZOgpdU6oWM"},"outputs":[],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","huggingface_model_name = \"gpt2\"\n","tokenizer = AutoTokenizer.from_pretrained(huggingface_model_name) # tokenizer 불러오기\n","tokenizer.pad_token = tokenizer.eos_token\n","model = AutoModelForCausalLM.from_pretrained(huggingface_model_name) # 모델 불러오기\n","model.generation_config.pad_token_id = tokenizer.pad_token_id\n","\n","input_text = \"My favorite sport is\"\n","encoded_input = tokenizer(input_text, return_tensors=\"pt\")\n","output = model.generate(**encoded_input, max_new_tokens=50)\n","response = tokenizer.decode(output[0], skip_special_tokens=True)\n","print(response)"]},{"cell_type":"markdown","metadata":{"id":"59e4WXqP6oWM"},"source":["### 프롬프트 엔지니어링 체험해보기\n","\n","Can you make GPT-2 to summarize or translate?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_c610OKY6oWM"},"outputs":[],"source":["prompt = \"\"\"Question: translate french word \"Merci\" to English  /Answer:\n","\"\"\"\n","encoded_input = tokenizer(prompt, return_tensors=\"pt\")\n","output = model.generate(\n","    **encoded_input,\n","    max_new_tokens=20,\n","    top_p=0.9,\n","    top_k=50,\n","    temperature = 0.7,\n","    do_sample=True,\n",")\n","response = tokenizer.decode(output[0], skip_special_tokens=True)\n","print(response)"]},{"cell_type":"code","source":["prompt = \"\"\"Question: translate \"Hello\" to French  /Answer:\n","\"\"\"\n","encoded_input = tokenizer(prompt, return_tensors=\"pt\")\n","output = model.generate(\n","    **encoded_input,\n","    max_new_tokens=20,\n","    top_p=0.9,\n","    top_k=50,\n","    temperature = 0.7,\n","    do_sample=True,\n",")\n","response = tokenizer.decode(output[0], skip_special_tokens=True)\n","print(response)"],"metadata":{"id":"NRajFIDMrBGU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"\"\"English: Hello\n","French: Bonjour\n","\n","English: How are you?\n","French: Comment ça va?\n","\n","English: I love you\n","French: Je t'aime\n","\n","English: Thank you\n","French: Merci\n","\n","English: Good morning\n","French: Bonjour\n","\n","English: Good night\n","French: Bonne nuit\n","\n","English: What time is it?\n","French: Quelle heure est-il?\n","\n","English: Where is the bathroom?\n","French: Où sont les toilettes?\n","\n","English: I am hungry\n","French: J'ai faim\n","\n","English: I am tired\n","French: Je suis fatigué(e)\n","\n","English: How much does it cost?\n","French: Combien ça coûte?\n","\n","English: Can you help me?\n","French: Pouvez-vous m'aider?\n","\n","English: I don’t understand\n","French: Je ne comprends pas\n","\n","English: Excuse me\n","French: Excusez-moi\n","\n","English: See you later\n","French: À bientôt\n","\n","English: I like you\n","French:\n","\"\"\"\n","encoded_input = tokenizer(prompt, return_tensors=\"pt\")\n","output = model.generate(\n","    **encoded_input,\n","    max_new_tokens=20,\n","    top_p=0.9,\n","    top_k=50,\n","    temperature = 0.7,\n","    do_sample=True,\n",")\n","response = tokenizer.decode(output[0], skip_special_tokens=True)\n","print(response)"],"metadata":{"id":"5Rlbkb46uJ9r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"\"\"In today's fast-paced world, technology plays a vital role in shaping the future. It has transformed the way we communicate, work, and even think. Innovations like artificial intelligence, machine learning, and blockchain are creating new opportunities while also presenting challenges. As we move forward, it's crucial to find a balance between progress and ethics, ensuring technology benefits everyone without compromising our values.\n","TL;DR:\n","\"\"\"\n","encoded_input = tokenizer(prompt, return_tensors=\"pt\")\n","output = model.generate(\n","    **encoded_input,\n","    max_new_tokens=20,\n","    top_p=0.9,\n","    top_k=50,\n","    temperature = 0.7,\n","    do_sample=True,\n",")\n","response = tokenizer.decode(output[0], skip_special_tokens=True)\n","print(response)"],"metadata":{"id":"x1n4AsWcvGvp"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}